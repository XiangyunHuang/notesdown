# 广义可加模型 {#chap:generalized-additive-models}

广义可加模型，主要参考 Simon N. Wood [@Wood_2017_Generalized] GAM  `mgcv::gam` 

- 大数据集 `mgcv::bam` 

广义可加模型（Generalized Additive Models，简称 GAM 模型）在 R 中的实现

- **gam** [@gam] 实现了《Statistical Models in S》[@Chambers_1992_Statistical] 中描述的所有广义可加模型
- **mgcv** [@Wood_2017_Generalized]
- **gss** [@Gu_2014_jss]
- **mda** [@mda]

 广义可加模型资源 <https://github.com/noamross/gam-resources>

Are GAMs implemented in R?

Package gam from CRAN implements all the Generalized Additive Models (GAM) functionality as described in the GAM chapter of the White Book. In particular, it implements backfitting with both local regression and smoothing splines, and is extendable. There is a gam() function for GAMs in package mgcv, but it is not an exact clone of what is described in the White Book (no lo() for example). Package gss can fit spline-based GAMs too. And if you can accept regression splines you can use glm(). For Gaussian GAMs you can use bruto() from package mda.


## mgcv

还可以用 broom 或 [broomExtra](https://github.com/IndrajeetPatil/broomExtra) 包整理拟合结果

拟合广义可加模型的 R 包还有 gam、 gamm4 和 VGAM

## splines {#subsec:spline-smooth}

> Bandwidth selection is an unresolved (and possibly unsolvable) problem in smoothing, so you're perfectly justified in trying/choosing an arbitrary value if it produces good pictures!
>
>   --- Adrian Baddeley (answering a user's question about the choice of smoothing parameter when using the `density.ppp()` function from the **spatstat** package) private communication (March 2013)
	  
MASS 也有平滑参数 KernSmooth 包 [@KernSmooth1995]
	  
样条和平滑 

```{r,results='hide',eval=FALSE}
# lowess 和 loess 的区别和联系 https://d.cosx.org/d/420981
# smooth  `Visualize' steps in Tukey's smoothers
demo("smooth", ask = FALSE)

Income <- read.table("http://faculty.marshall.usc.edu/gareth-james/ISL/Income2.csv", sep = ",", header = TRUE)
mod <- loess(Income ~ Education + Seniority, data = Income)

x_Edu <- seq(min(Income$Education), max(Income$Education), length.out = 30)
x_Sen <- seq(min(Income$Seniority), max(Income$Seniority), length.out = 30)

pred_func <- function(x1, x2) {
  predict(mod, newdata = cbind(x1, x2))
}

y_income <- outer(x_Edu, x_Sen, pred_func)

point_pmat <- persp(
  x = x_Edu, y = x_Sen, z = y_income, theta = 45, phi = 35, col = "lightblue",
  xlab = "Years of Education", ylab = "Seniority", zlab = "Income"
)
points(trans3d(x = Income$Education, y = Income$Seniority, z = Income$Income, pmat = point_pmat), col = "red", pch = 16)
for (i in 1:dim(Income)[1]) {
  z <- seq(Income$Income[i], pred_func(Income$Education[i], Income$Seniority[i]), length.out = 10)
  lines(trans3d(x = Income$Education[i], y = Income$Seniority[i], z = z, pmat = point_pmat))
}
```

## brms

梯度提升机，从统计的角度看 boosting 算法，可加逻辑回归

经典导读：多元适应性（自适应）回归样条 multivariate adaptive regression splines

- mda: Mixture and Flexible Discriminant Analysis
- earth: Multivariate Adaptive Regression Splines

1. Friedman, Jerome H. 1991. Multivariate Adaptive Regression Splines. The Annals of Statistics. 19(1):1--67. <https://doi.org/10.1214/aos/1176347963>
1. Friedman, Jerome H. 2001. Greedy function approximation: A gradient boosting machine. The Annals of Statistics. 29(5):1189--1232. <https://doi.org/10.1214/aos/1013203451>
1. Friedman, Jerome H., Trevor Hastie and Robert Tibshirani. Additive Logistic Regression: A Statistical View of Boosting. The Annals of Statistics. 28(2): 337--374. <http://www.jstor.org/stable/2674028>
